{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915623e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install required packages (The -q flag means quiet installation)\n",
    "! pip install ultralytics -q\n",
    "! pip install streamlit -q  # <<<--- ADDED: Explicitly install Streamlit\n",
    "! pip install pyngrok -q\n",
    "! pip install roboflow -q\n",
    "! pip install opencv-python-headless -q # Ensure CV2 is ready for Streamlit\n",
    "\n",
    "# 2. Mount Google Drive for saving model weights\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 3. Clean up any previous dataset folder to ensure a clean download\n",
    "!rm -rf mask-hairnet-gloves-iopkp-1  \n",
    "\n",
    "# 4. Load the dataset\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"vLBWuwn1rsPb9kU40N44\")\n",
    "project = rf.workspace(\"workshopr\").project(\"mask-hairnet-gloves-iopkp\")\n",
    "version = project.version(1)\n",
    "\n",
    "# CRITICAL: Download in standard 'yolov11' format\n",
    "dataset = version.download(\"yolov11\") \n",
    "\n",
    "# Define the paths for the next steps\n",
    "DATASET_DIR = dataset.location\n",
    "DATA_YAML_PATH = f\"{DATASET_DIR}/data.yaml\"\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset successfully downloaded to: {DATASET_DIR}\")\n",
    "print(f\"data.yaml path: {DATA_YAML_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3524338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Ensure Colab is using a GPU (Runtime -> Change runtime type)\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Load a pre-trained detection model (nano-size)\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# --- Start Training ---\n",
    "# - task='detect': Activates the standard Axis-Aligned Bounding Box mode\n",
    "results = model.train(\n",
    "    task='detect',\n",
    "    data=DATA_YAML_PATH,\n",
    "    epochs=100, \n",
    "    imgsz=640,\n",
    "    patience=20, \n",
    "    batch=16, \n",
    "    name='ppe_yolo11_detect_v1'\n",
    ")\n",
    "\n",
    "# --- Backup Model ---\n",
    "MODEL_SAVE_PATH = '/content/runs/detect/ppe_yolo11_detect_v1/weights/best.pt'\n",
    "! cp {MODEL_SAVE_PATH} /content/drive/MyDrive/best_ppe_yolo11_model.pt\n",
    "print(f\"\\nModel saved to Drive: /content/drive/MyDrive/best_ppe_yolo11_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the final trained model weights\n",
    "BEST_MODEL_PATH = '/content/runs/detect/ppe_yolo11_detect_v1/weights/best.pt'\n",
    "model = YOLO(BEST_MODEL_PATH, task='detect')\n",
    "\n",
    "# 1. Validate the model (Calculates required mAP metrics)\n",
    "print(\"\\n--- Running Final Validation ---\")\n",
    "metrics = model.val(\n",
    "    data=DATA_YAML_PATH,\n",
    "    split='test' # Validate against the test set\n",
    ")\n",
    "print(f\"\\n‚úÖ Model mAP50-95 Score: {metrics.box.map}\")\n",
    "print(f\"‚úÖ Model mAP50 Score: {metrics.box.map50}\")\n",
    "\n",
    "\n",
    "# 2. Run Inference on a sample image (optional visualization)\n",
    "SAMPLE_IMAGE_DIR = f'{DATASET_DIR}/test/images'\n",
    "sample_images = glob.glob(f'{SAMPLE_IMAGE_DIR}/*.jpg')\n",
    "\n",
    "if sample_images:\n",
    "    sample_path = sample_images[0]\n",
    "    print(f\"\\n--- Running Inference on Sample Image: {Path(sample_path).name} ---\")\n",
    "    \n",
    "    # Run prediction and save results\n",
    "    results = model.predict(sample_path, save=True, conf=0.25, name='sample_inference', exist_ok=True)\n",
    "    \n",
    "    # Display the annotated image\n",
    "    display_path = Path('/content/runs/detect/sample_inference') / Path(sample_path).name\n",
    "    print(f\"\\n‚úÖ Displaying annotated image:\")\n",
    "    display(Image(filename=str(display_path)))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Could not find a sample image in the test set for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import cv2\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration (CRITICAL: Must match your training setup) ---\n",
    "MODEL_PATH = 'best_ppe_yolo11_model.pt' \n",
    "# Default path created by Roboflow in Step 1\n",
    "DATA_YAML_PATH = '/content/mask-hairnet-gloves-iopkp-1/data.yaml' \n",
    "\n",
    "# Load class names from the Roboflow data.yaml\n",
    "try:\n",
    "    with open(DATA_YAML_PATH, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    CLASS_NAMES = data_config.get('names', [])\n",
    "    if not CLASS_NAMES:\n",
    "        st.error(\"Could not load class names from data.yaml.\")\n",
    "        CLASS_NAMES = ['mask', 'glove', 'haircap'] # Fallback\n",
    "except Exception as e:\n",
    "    st.error(f\"Error loading data.yaml: {e}. Using default class names.\")\n",
    "    CLASS_NAMES = ['mask', 'glove', 'haircap'] # Fallback\n",
    "\n",
    "# Load the model once at startup (Streamlit caching for performance)\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    # Load the model using the correct task='detect'\n",
    "    return YOLO(MODEL_PATH, task='detect') \n",
    "\n",
    "MODEL = load_model()\n",
    "\n",
    "# Set Streamlit page layout\n",
    "st.set_page_config(\n",
    "    page_title=\"YOLOv11 PPE Detector\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# --- Processing Logic: Runs detection and draws boxes ---\n",
    "def process_frame(frame, conf_threshold):\n",
    "    \"\"\"Runs standard detection inference and draws bounding boxes on the frame.\"\"\"\n",
    "    \n",
    "    # Run prediction, forcing GPU if available (device='0')\n",
    "    results = MODEL.predict(frame, conf=conf_threshold, verbose=False, device='0')[0]\n",
    "    \n",
    "    annotator = Annotator(frame, line_width=2, example=CLASS_NAMES)\n",
    "    \n",
    "    # Object Counter initialization (Required feature)\n",
    "    object_count = {name: 0 for name in CLASS_NAMES}\n",
    "    \n",
    "    if results.boxes:\n",
    "        for box in results.boxes:\n",
    "            c = int(box.cls[0]) # Class index\n",
    "            label = f\"{CLASS_NAMES[c]} {box.conf[0]:.2f}\"\n",
    "            \n",
    "            # Draw the Axis-Aligned Bounding Box (AABB)\n",
    "            xyxy = box.xyxy[0].tolist()\n",
    "            annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "            \n",
    "            # Update object count\n",
    "            if 0 <= c < len(CLASS_NAMES):\n",
    "                object_count[CLASS_NAMES[c]] += 1\n",
    "            \n",
    "    # Display the object count in the sidebar (Required feature)\n",
    "    st.sidebar.subheader(\"Detected Objects Count\")\n",
    "    for name, count in object_count.items():\n",
    "        st.sidebar.markdown(f\"**{name.capitalize()}:** `{count}`\")\n",
    "\n",
    "    return annotator.result()\n",
    "\n",
    "\n",
    "# --- Main Dashboard Structure ---\n",
    "st.title(\"üõ°Ô∏è Safety Gear (PPE) Object Detector\")\n",
    "st.sidebar.header(\"Model Configuration\")\n",
    "\n",
    "# Sidebar controls (Required feature: Confidence slider)\n",
    "confidence = st.sidebar.slider(\n",
    "    \"Select Confidence Threshold (Minimum prediction score)\", \n",
    "    min_value=0.01, \n",
    "    max_value=1.0, \n",
    "    value=0.25 # Default value\n",
    ")\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "source_option = st.sidebar.radio(\"Select Input Source\", ('Image Upload', 'Video Upload'))\n",
    "\n",
    "# --- Source Handlers ---\n",
    "if source_option == 'Image Upload':\n",
    "    uploaded_file = st.file_uploader(\"Upload an image for detection\", type=['jpg', 'jpeg', 'png'])\n",
    "    if uploaded_file is not None:\n",
    "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
    "        image = cv2.imdecode(file_bytes, 1)\n",
    "\n",
    "        st.subheader(\"Detected Image\")\n",
    "        with st.spinner('Processing Image...'):\n",
    "            processed_image = process_frame(image, confidence)\n",
    "            st.image(processed_image, channels=\"BGR\", use_column_width=True)\n",
    "            st.success(\"Detection complete.\")\n",
    "\n",
    "elif source_option == 'Video Upload':\n",
    "    # This is crucial for your demo, as it shows real-time processing\n",
    "    uploaded_file = st.file_uploader(\"Upload a video for detection (e.g., MP4)\", type=['mp4', 'avi', 'mov'])\n",
    "    if uploaded_file is not None:\n",
    "        st.subheader(\"Video Detection Feed (Real-time Simulation)\")\n",
    "        \n",
    "        # Save uploaded video to a temporary file\n",
    "        tfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "        tfile.write(uploaded_file.read())\n",
    "        \n",
    "        cap = cv2.VideoCapture(tfile.name)\n",
    "        st_frame = st.empty()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process frame and display\n",
    "            processed_frame = process_frame(frame, confidence)\n",
    "            st_frame.image(processed_frame, channels=\"BGR\", use_column_width=True)\n",
    "            \n",
    "        cap.release()\n",
    "        st.success(\"Video processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d27589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Copy the trained model weights to the current directory (needed by app.py)\n",
    "! cp /content/runs/detect/ppe_yolo11_detect_v1/weights/best.pt /content/best_ppe_yolo11_model.pt\n",
    "\n",
    "# The Streamlit server runs on port 8501\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# 2. Terminate any previous ngrok tunnels\n",
    "try:\n",
    "    ngrok.kill()\n",
    "    print(\"Previous ngrok tunnels terminated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not terminate ngrok: {e}\")\n",
    "\n",
    "# 3. Start the Streamlit app in the background\n",
    "print(\"Starting Streamlit app...\")\n",
    "# Use 'python3 -m streamlit' to ensure the correct module is executed\n",
    "proc = subprocess.Popen(\n",
    "    [\"python3\", \"-m\", \"streamlit\", \"run\", \"app.py\", \"--logger.level\", \"error\"],\n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE, \n",
    "    text=True,\n",
    "    shell=False\n",
    ")\n",
    "time.sleep(8) # Wait longer for Streamlit to fully initialize\n",
    "\n",
    "# 4. Check if the Streamlit process started correctly\n",
    "if proc.poll() is not None:\n",
    "    # If the process stopped immediately, print the captured logs\n",
    "    print(\"üö® FATAL ERROR: Streamlit failed to start. (This should not happen now)\")\n",
    "    stdout, stderr = proc.communicate()\n",
    "    print(\"\\n--- Streamlit STDOUT (Logs) ---\")\n",
    "    print(stdout)\n",
    "    print(\"\\n--- Streamlit STDERR (Error Traceback) ---\")\n",
    "    print(stderr)\n",
    "else:\n",
    "    # 5. Start the ngrok tunnel on the Streamlit port\n",
    "    print(\"Attempting to connect via ngrok...\")\n",
    "    try:\n",
    "        # NOTE: ngrok may ask you to set an auth token if you haven't done so.\n",
    "        public_url = ngrok.connect(8501)\n",
    "        print(f\"üéâ Streamlit Dashboard Live at: {public_url}\")\n",
    "        print(\"üí° NOTE: Click the link above. Keep this cell running to keep the link active for your demo.\")\n",
    "        # Keep the cell alive indefinitely\n",
    "        time.sleep(9999999) \n",
    "    except Exception as e:\n",
    "        print(f\"üö® NGROK ERROR: {e}\")\n",
    "        print(\"Check if you need to set your ngrok auth token. Use !ngrok config add-authtoken <YOUR_TOKEN> in a new cell.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
